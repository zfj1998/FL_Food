{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibSVM:\n",
    "    def __init__(self, C = 1, lr = 0.01):\n",
    "        '''\n",
    "        超参数包括松弛变量C和学习率lr\n",
    "        要学习的参数是一个线性超平面的权重和偏置\n",
    "        '''\n",
    "        self.C = C\n",
    "        self.lr = lr\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def train(self):\n",
    "        self.weights.requires_grad = True\n",
    "        self.bias.requires_grad = True\n",
    "        \n",
    "    def eval(self):\n",
    "        self.weights.requires_grad = False\n",
    "        self.bias.requires_grad = False\n",
    "    \n",
    "    def fit(self, X, y, max_iters = 1000):\n",
    "        '''\n",
    "        X是数据张量, size(n,m)\n",
    "        数据维度m, 数据数目n\n",
    "        y是二分类标签, 只能是1或-1\n",
    "        '''\n",
    "        n,m = X.shape\n",
    "        y = y.reshape(-1,1)\n",
    "        self.weights = torch.randn(m,1)\n",
    "        self.bias = torch.randn(1)\n",
    "        self.train()\n",
    "        \n",
    "        for step in range(max_iters):\n",
    "            out = X.mm(self.weights)+self.bias # 前向计算\n",
    "            # 损失计算\n",
    "            loss = 0.5*self.weights.T.mm(self.weights)+\\\n",
    "            self.C*torch.sum(F.relu(-y*out+1))\n",
    "            # 自动求导\n",
    "            loss.backward()\n",
    "            # 梯度下降\n",
    "            self.weights.data -= self.lr*self.weights.grad.data\n",
    "            self.bias.data -= self.lr*self.bias.grad.data\n",
    "            self.weights.grad.data.zero_()\n",
    "            self.bias.grad.data.zero_()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def predict(self, x, raw = False):\n",
    "        self.eval()\n",
    "        out = x.mm(self.weights)+self.bias\n",
    "        if raw: return out\n",
    "        else: return torch.sign(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenyizhou\n"
     ]
    }
   ],
   "source": [
    "%cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_datas = pd.read_csv('epi_r_filtered_5.csv')\n",
    "epi_datas = epi_datas.values\n",
    "x = epi_datas[:,1:]\n",
    "y = epi_datas[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y==0.0]=1\n",
    "y[y==1.25]=1\n",
    "y[y==1.875]=1\n",
    "y[y==2.5]=1\n",
    "y[y==3.125]=1\n",
    "y[y==3.75]=1\n",
    "y[y==4.375]=-1\n",
    "y[y==5.0]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "standar_data = StandardScaler()\n",
    "standar_data.fit(x)\n",
    "standar_datax = standar_data.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(standar_datax,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train,dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LibSVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[172639.5156]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    # 获取常见的4个值，用于系列指标计算\n",
    "    TN, FP, FN, TP = np.fromiter((sum(\n",
    "        bool(j >> 1) == bool(y_true[i]) and\n",
    "        bool(j & 1) == bool(y_pred[i])\n",
    "        for i in range(len(y_true))\n",
    "    ) for j in range(4)), float)\n",
    "\n",
    "    Accuracy = (TN + TP) / (TN + FP + FN + TP + 1e-8)\n",
    "    Precision = TP / (TP + FP + 1e-8)\n",
    "    # True Positive Rate\n",
    "    Recall = TP / (TP + FN + 1e-8)\n",
    "    # False Positive Rate\n",
    "    FPR = FP / (FP + TN + 1e-8)\n",
    "\n",
    "    print(\"Precision\", Precision)\n",
    "    print(\"Recall\", Recall)\n",
    "    print('Accuracy',Accuracy)\n",
    "\n",
    "    # F_measure = 2 * Recall * Precision / (Recall + Precision + 1e-8)\n",
    "    # g_mean = np.sqrt((TN / (TN + FP + 1e-8)) * (TP / (TP + FN + 1e-8)))\n",
    "    # Balance = 1 - np.sqrt((0 - FPR) ** 2 + (1 - Recall) ** 2) / np.sqrt(2)\n",
    "    MCC = (TP * TN - FN * FP) / np.sqrt((TP + FN) * (TP + FP) * (FN + TN) * (FP + TN) + 1e-8)\n",
    "\n",
    "    # 当F_measure中θ值为2时\n",
    "    F_2 = 5 * Recall * Precision / (4 * Recall + Precision + 1e-8)\n",
    "    # G_measure = 2 * Recall * (1 - FPR) / (Recall + (1 - FPR) + 1e-8)\n",
    "    # NMI = normalized_mutual_info_score(y_true, y_pred, average_method=\"arithmetic\")\n",
    "\n",
    "    # 返回所有指标值 vars() 函数返回对象object的属性和属性值的字典对象。\n",
    "    y_pred = vars()\n",
    "    # 该字典不返回'y_true', 'y_pred', \"TN\", \"FP\", \"FN\", \"TP\"这些key值\n",
    "    return {k: y_pred[k] for k in reversed(list(y_pred)) if k not in ['y_true', 'y_pred', \"TN\", \"FP\", \"FN\", \"TP\", \"FPR\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.9999999999976191\n",
      "Recall 0.9999999999976191\n",
      "Accuracy 0.9999999999976191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'F_2': 0.9999999979976192,\n",
       " 'MCC': 0.0,\n",
       " 'Recall': 0.9999999999976191,\n",
       " 'Precision': 0.9999999999976191,\n",
       " 'Accuracy': 0.9999999999976191}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
