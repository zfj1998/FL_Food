{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3.0: 2198, 2.0: 1457, 4.0: 880, 5.0: 175, 1.0: 163, 0.0: 20, 6.0: 5})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redwine_data = pd.read_csv('../data/winequality-red.csv',sep=';')\n",
    "redwine_data = pd.read_csv('../data/winequality-white.csv',sep=';')\n",
    "Redwine_datas = redwine_data.values\n",
    "x = Redwine_datas[:,:11]\n",
    "y = Redwine_datas[:,11]\n",
    "y = y-3\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(x).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassifier(nn.Module):\n",
    "    def __init__(self, first, second, third):\n",
    "        super(MyClassifier,self).__init__()\n",
    "        self.fc1 = nn.Linear(11,first)\n",
    "        self.fc2 = nn.Linear(first,second)\n",
    "        self.fc3 = nn.Linear(second,third)\n",
    "        self.fc4 = nn.Linear(third,7)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "             \n",
    "    def predict(self,x):\n",
    "        pred = F.softmax(self.forward(x), dim=0)\n",
    "        ans = torch.argmax(pred, dim=1)\n",
    "        return torch.tensor(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassifier(nn.Module):\n",
    "    def __init__(self, first, second):\n",
    "        super(MyClassifier,self).__init__()\n",
    "        self.fc1 = nn.Linear(11,first)\n",
    "        self.fc2 = nn.Linear(first,second)\n",
    "        self.fc3 = nn.Linear(second,7)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "             \n",
    "    def predict(self,x):\n",
    "        pred = F.softmax(self.forward(x), dim=0)\n",
    "        ans = torch.argmax(pred, dim=1)\n",
    "        return torch.tensor(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideal_params = [(22, 11),(22, 22),(22, 7)]\n",
    "# ideal_params = [(22, 11, 7)]\n",
    "ideal_params = [(22, 22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zfj/anaconda3/envs/torch1.4/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.0742437839508057\n",
      "loss:1.2111685276031494\n",
      "loss:1.1219303607940674\n",
      "loss:1.0857497453689575\n",
      "loss:1.0741232633590698\n",
      "loss:1.0527595281600952\n",
      "loss:1.0603199005126953\n",
      "loss:1.055572509765625\n",
      "loss:1.0324152708053589\n",
      "loss:1.0253757238388062\n",
      "loss:1.0255614519119263\n",
      "loss:1.0174503326416016\n",
      "loss:1.0176271200180054\n",
      "loss:1.014363169670105\n",
      "loss:0.9987996220588684\n",
      "loss:1.0045017004013062\n",
      "loss:0.9891347885131836\n",
      "loss:0.9963043928146362\n",
      "loss:0.9853063821792603\n",
      "loss:0.9750410914421082\n",
      "loss:0.9709444046020508\n",
      "loss:0.976233184337616\n",
      "loss:0.9685924053192139\n",
      "loss:0.9580557346343994\n",
      "loss:0.9559205770492554\n",
      "loss:0.9576398730278015\n",
      "loss:0.9489246606826782\n",
      "loss:0.9435476064682007\n",
      "loss:0.9398589134216309\n",
      "loss:0.9368875622749329\n",
      "loss:0.9300890564918518\n",
      "loss:0.9364582300186157\n",
      "loss:0.9287558197975159\n",
      "loss:0.9235302805900574\n",
      "loss:0.9243490695953369\n",
      "loss:0.9186230301856995\n",
      "loss:0.9121924042701721\n",
      "loss:0.918719470500946\n",
      "loss:0.9122540354728699\n",
      "loss:0.9107390642166138\n",
      "loss:0.9085294604301453\n",
      "loss:1.065458059310913\n",
      "loss:0.9083465337753296\n",
      "loss:0.8990974426269531\n",
      "loss:0.8967706561088562\n",
      "loss:0.8962340354919434\n",
      "loss:0.8950069546699524\n",
      "loss:0.8954558968544006\n",
      "loss:0.8978055119514465\n",
      "loss:0.9024161100387573\n",
      "loss:0.8941603899002075\n",
      "loss:0.888383150100708\n",
      "loss:0.8855103254318237\n",
      "loss:0.8895730376243591\n",
      "loss:0.9001101851463318\n",
      "loss:0.9011921286582947\n",
      "loss:0.8857213854789734\n",
      "loss:0.8807262182235718\n",
      "loss:0.8896034955978394\n",
      "loss:0.8815333247184753\n",
      "loss:0.8739749193191528\n",
      "loss:0.8705284595489502\n",
      "loss:0.8735889792442322\n",
      "loss:0.8811815977096558\n",
      "loss:0.8810482025146484\n",
      "loss:0.868198037147522\n",
      "loss:0.8946595788002014\n",
      "loss:0.8637067675590515\n",
      "loss:0.8746755123138428\n",
      "loss:0.8659989833831787\n",
      "loss:0.8765705227851868\n",
      "loss:0.9203475713729858\n",
      "loss:0.8600902557373047\n",
      "loss:0.8769856095314026\n",
      "loss:0.8585648536682129\n",
      "loss:0.8670126795768738\n",
      "loss:0.8545939326286316\n",
      "loss:0.8512071967124939\n",
      "loss:0.8649250268936157\n",
      "loss:0.8509320616722107\n",
      "loss:0.8536728620529175\n",
      "loss:0.8495597839355469\n",
      "loss:0.8496016263961792\n",
      "loss:0.8598000407218933\n",
      "loss:0.8494763970375061\n",
      "loss:0.8541154861450195\n",
      "loss:0.8548662066459656\n",
      "loss:0.8604224324226379\n",
      "loss:0.8437815308570862\n",
      "loss:1.0386488437652588\n",
      "loss:0.8493542075157166\n",
      "loss:0.8463937640190125\n",
      "loss:0.8403581976890564\n",
      "loss:0.8405004143714905\n",
      "loss:0.841069221496582\n",
      "loss:0.8476672172546387\n",
      "loss:0.8442085385322571\n",
      "loss:0.8426460027694702\n",
      "loss:0.8503889441490173\n",
      "loss:0.8394665718078613\n",
      "loss:0.8672386407852173\n",
      "loss:0.8448439836502075\n",
      "loss:0.8442341089248657\n",
      "loss:0.8448394536972046\n",
      "loss:0.8381329774856567\n",
      "loss:0.8405348062515259\n",
      "loss:0.8585174679756165\n",
      "loss:0.8482972979545593\n",
      "loss:0.8372107148170471\n",
      "loss:0.8442513346672058\n",
      "loss:0.833379864692688\n",
      "loss:0.8328724503517151\n",
      "loss:0.8433845639228821\n",
      "loss:0.835791289806366\n",
      "loss:0.8367502093315125\n",
      "loss:0.8358617424964905\n",
      "loss:0.8449835777282715\n",
      "loss:0.8368624448776245\n",
      "loss:0.8325695395469666\n",
      "loss:0.8339675664901733\n",
      "loss:0.8391179442405701\n",
      "loss:0.8292986750602722\n",
      "loss:0.8311803340911865\n",
      "loss:0.8293372988700867\n",
      "loss:0.83323073387146\n",
      "loss:0.8293175101280212\n",
      "loss:0.8274277448654175\n",
      "loss:0.8279798030853271\n",
      "loss:0.8372921943664551\n",
      "loss:0.8243778347969055\n",
      "loss:0.8278930187225342\n",
      "loss:0.8300683498382568\n",
      "loss:0.8230137825012207\n",
      "loss:0.8305584788322449\n",
      "loss:0.8679339289665222\n",
      "loss:0.8492271304130554\n",
      "loss:0.8217395544052124\n",
      "loss:0.8295743465423584\n",
      "loss:0.8250247240066528\n",
      "loss:0.8301971554756165\n",
      "loss:0.8250369429588318\n",
      "loss:0.8288633823394775\n",
      "loss:0.8440180420875549\n",
      "loss:0.8520404696464539\n",
      "loss:0.826949954032898\n",
      "loss:0.825675904750824\n",
      "loss:0.8186406493186951\n",
      "loss:0.8186647891998291\n",
      "loss:0.8803955316543579\n",
      "loss:0.8613623976707458\n",
      "loss:0.8191119432449341\n",
      "loss:0.826788067817688\n",
      "loss:0.8187069296836853\n",
      "loss:0.8256109356880188\n",
      "loss:0.8285813331604004\n",
      "loss:0.8298783302307129\n",
      "loss:0.8303270936012268\n",
      "loss:0.8266569375991821\n",
      "loss:0.820796012878418\n",
      "loss:0.8350343704223633\n",
      "loss:0.8170487880706787\n",
      "loss:0.8235744833946228\n",
      "loss:0.8181398510932922\n",
      "loss:0.8183725476264954\n",
      "loss:0.815858006477356\n",
      "loss:0.8213521838188171\n",
      "loss:0.8154065608978271\n",
      "loss:0.8215510249137878\n",
      "loss:0.8244727253913879\n",
      "loss:0.8566734790802002\n",
      "loss:0.8155901432037354\n",
      "loss:0.8307751417160034\n",
      "loss:0.8179267048835754\n",
      "loss:0.8300658464431763\n",
      "loss:0.8126410841941833\n",
      "loss:0.8141186237335205\n",
      "loss:0.8129680752754211\n",
      "loss:0.8127076029777527\n",
      "loss:0.8149682283401489\n",
      "loss:0.8387306332588196\n",
      "loss:0.8196938037872314\n",
      "loss:0.8224549889564514\n",
      "loss:0.8126273155212402\n",
      "loss:0.8196742534637451\n",
      "loss:0.8189327716827393\n",
      "loss:0.8263223171234131\n",
      "loss:0.811809241771698\n",
      "loss:0.8222597241401672\n",
      "loss:0.8502743244171143\n",
      "loss:0.8222022652626038\n",
      "loss:0.8359260559082031\n",
      "loss:0.8400390148162842\n",
      "loss:0.8154389262199402\n",
      "loss:0.8155495524406433\n",
      "loss:0.8123406767845154\n",
      "loss:0.8147191405296326\n",
      "loss:0.8202196955680847\n",
      "loss:0.816889762878418\n",
      "loss:0.8198294043540955\n",
      "loss:0.8112907409667969\n",
      "loss:0.8168966174125671\n",
      "loss:0.814490795135498\n",
      "loss:0.8239049315452576\n",
      "loss:0.8183355331420898\n",
      "loss:0.8481418490409851\n",
      "loss:0.813018262386322\n",
      "loss:0.8162626624107361\n",
      "loss:0.8139411807060242\n",
      "loss:0.80988609790802\n",
      "loss:0.8465445041656494\n",
      "loss:0.8188837170600891\n",
      "loss:0.8303620219230652\n",
      "loss:0.8085104823112488\n",
      "loss:0.8124035000801086\n",
      "loss:0.8151800036430359\n",
      "loss:0.816362738609314\n",
      "loss:0.8124322891235352\n",
      "loss:0.8297067284584045\n",
      "loss:0.8133432865142822\n",
      "loss:0.8187731504440308\n",
      "loss:0.8187112212181091\n",
      "loss:0.8128238320350647\n",
      "loss:0.8157817721366882\n",
      "loss:0.8121362924575806\n",
      "loss:0.8102280497550964\n",
      "loss:0.825027585029602\n",
      "loss:0.817064106464386\n",
      "loss:0.8153442144393921\n",
      "loss:0.8155374526977539\n",
      "loss:0.8081153631210327\n",
      "loss:0.8057430982589722\n",
      "loss:0.805911123752594\n",
      "loss:0.8125139474868774\n",
      "loss:0.8123775124549866\n",
      "loss:0.8322121500968933\n",
      "loss:0.8145890235900879\n",
      "loss:0.8423027396202087\n",
      "loss:0.8245278596878052\n",
      "loss:0.8044560551643372\n",
      "loss:0.828217089176178\n",
      "loss:0.8079634308815002\n",
      "loss:0.8049799799919128\n",
      "loss:0.8081406354904175\n",
      "loss:0.8038725852966309\n",
      "loss:0.8057582974433899\n",
      "loss:0.8235810399055481\n",
      "loss:0.8102713227272034\n",
      "loss:0.8170093297958374\n",
      "loss:0.8249642848968506\n",
      "loss:0.8138672113418579\n",
      "loss:0.842982828617096\n",
      "loss:0.8039911985397339\n",
      "loss:0.8049507737159729\n",
      "loss:0.8108921051025391\n",
      "loss:0.8070774674415588\n",
      "loss:0.8029000163078308\n",
      "loss:0.8471143245697021\n",
      "loss:0.8156470060348511\n",
      "loss:0.8748290538787842\n",
      "loss:0.820690393447876\n",
      "loss:0.8136600852012634\n",
      "loss:0.8072682023048401\n",
      "loss:0.8062685132026672\n",
      "loss:0.8104782700538635\n",
      "loss:0.8049415946006775\n",
      "loss:0.8054648041725159\n",
      "loss:0.8157291412353516\n",
      "loss:0.8146505951881409\n",
      "loss:0.8138697147369385\n",
      "loss:0.8258152008056641\n",
      "loss:0.8134461641311646\n",
      "loss:0.8013535737991333\n",
      "loss:0.8076084852218628\n",
      "loss:0.8121528625488281\n",
      "loss:0.8065438866615295\n",
      "loss:0.8136548399925232\n",
      "loss:0.8211399912834167\n",
      "loss:0.8099353313446045\n",
      "loss:0.8144349455833435\n",
      "loss:0.8151409029960632\n",
      "loss:0.8082216382026672\n",
      "loss:0.8206164836883545\n",
      "loss:0.821262776851654\n",
      "loss:0.8110234141349792\n",
      "loss:0.8058898448944092\n",
      "loss:0.8159705400466919\n",
      "loss:0.8126024603843689\n",
      "loss:0.8097752332687378\n",
      "loss:0.8015232682228088\n",
      "loss:0.8030468225479126\n",
      "loss:0.8080720901489258\n",
      "loss:0.8183472156524658\n",
      "loss:0.8111426830291748\n",
      "loss:0.8005184531211853\n",
      "loss:0.8477815389633179\n",
      "loss:0.8044970035552979\n",
      "loss:0.8307602405548096\n",
      "loss:0.8035731911659241\n",
      "loss:0.8147642016410828\n",
      "loss:0.8061003684997559\n",
      "loss:0.8383955955505371\n",
      "loss:0.8466562628746033\n",
      "loss:0.81339031457901\n",
      "loss:0.8098269104957581\n",
      "loss:0.8103933334350586\n",
      "loss:0.9085296392440796\n",
      "loss:0.8089764714241028\n",
      "loss:0.8024391531944275\n",
      "loss:0.8141765594482422\n",
      "loss:0.8056193590164185\n",
      "loss:0.8183885812759399\n",
      "loss:0.8068233728408813\n",
      "loss:0.8124746680259705\n",
      "loss:0.8247500061988831\n",
      "loss:0.8150977492332458\n",
      "loss:0.8057817816734314\n",
      "loss:0.8061856627464294\n",
      "loss:0.8078939318656921\n",
      "loss:0.8165638446807861\n",
      "loss:0.8296913504600525\n",
      "loss:0.863339364528656\n",
      "loss:0.8160781860351562\n",
      "loss:0.8179942965507507\n",
      "loss:0.8120755553245544\n",
      "loss:0.8019408583641052\n",
      "loss:0.8226087093353271\n",
      "loss:0.8063235282897949\n",
      "loss:0.8325096368789673\n",
      "loss:0.8101206421852112\n",
      "loss:0.8029060959815979\n",
      "loss:0.8234128952026367\n",
      "loss:0.8091919422149658\n",
      "loss:0.8060116171836853\n",
      "loss:0.8099368810653687\n",
      "loss:0.8176416754722595\n",
      "loss:0.8060518503189087\n",
      "loss:0.8056008219718933\n",
      "loss:0.8222127556800842\n",
      "loss:0.8061531782150269\n",
      "loss:0.8159321546554565\n",
      "loss:0.8154314756393433\n",
      "loss:0.8150036334991455\n",
      "loss:0.8128564357757568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.8053483963012695\n",
      "loss:0.8055228590965271\n",
      "loss:0.817302405834198\n",
      "loss:0.8389367461204529\n",
      "loss:0.8455371260643005\n",
      "loss:0.8277912735939026\n",
      "loss:0.8002198934555054\n",
      "loss:0.8026076555252075\n",
      "loss:0.8084164261817932\n",
      "loss:0.8087930083274841\n",
      "loss:0.8215698599815369\n",
      "loss:0.8150925636291504\n",
      "loss:0.809500515460968\n",
      "loss:0.8473733067512512\n",
      "loss:0.8197570443153381\n",
      "loss:0.8119880557060242\n",
      "loss:0.80524742603302\n",
      "loss:0.8070741295814514\n",
      "loss:0.8262032866477966\n",
      "loss:0.8104831576347351\n",
      "loss:0.8085861206054688\n",
      "loss:0.8092619180679321\n",
      "loss:0.8304311633110046\n",
      "loss:0.8136868476867676\n",
      "loss:0.8138731718063354\n",
      "loss:0.8138510584831238\n",
      "loss:0.8111585378646851\n",
      "loss:0.8260144591331482\n",
      "loss:0.8486096858978271\n",
      "loss:0.820227324962616\n",
      "loss:0.8255468606948853\n",
      "loss:0.836240828037262\n",
      "loss:0.8184915781021118\n",
      "loss:0.8149131536483765\n",
      "loss:0.8002826571464539\n",
      "loss:0.8152766823768616\n",
      "loss:0.8203016519546509\n",
      "loss:0.801080584526062\n",
      "loss:0.8007298111915588\n",
      "loss:0.8099176287651062\n",
      "loss:0.7974297404289246\n",
      "loss:0.8047104477882385\n",
      "loss:0.7986962795257568\n",
      "loss:0.7996523976325989\n",
      "loss:0.8305320739746094\n",
      "loss:0.8048115372657776\n",
      "loss:0.8065117597579956\n",
      "loss:0.8025808930397034\n",
      "loss:0.8122453689575195\n",
      "loss:0.8173818588256836\n",
      "loss:0.7963970303535461\n",
      "loss:0.8159295320510864\n",
      "loss:0.7973024845123291\n",
      "loss:0.799343466758728\n",
      "loss:0.8032291531562805\n",
      "loss:0.8079771995544434\n",
      "loss:0.8060011267662048\n",
      "with params (22, 22): minloss:0.7963970303535461  maxtrain:0.5705950991831972  maxtest:0.4489795918367347\n"
     ]
    }
   ],
   "source": [
    "for ideal_param in ideal_params:\n",
    "    model = MyClassifier(*ideal_param)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    epochs = 20000\n",
    "    losses = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        x_pred = model.forward(x_train)\n",
    "        loss = criterion(x_pred,y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%50 == 0:\n",
    "            losses.append(loss.item())\n",
    "            train_accuracy.append(accuracy_score(model.predict(x_train), y_train))\n",
    "            test_accuracy.append(accuracy_score(model.predict(x_test), y_test))\n",
    "            print('loss:{}'.format(loss.item()))\n",
    "                \n",
    "    min_loss = min(losses)\n",
    "    max_train = max(train_accuracy)\n",
    "    max_test = max(test_accuracy)\n",
    "    \n",
    "    print('with params {}: minloss:{}  maxtrain:{}  maxtest:{}'.format(ideal_param, min_loss, max_train, max_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red 1w epoch\n",
    "# with params (11, 11): minloss:0.6768573522567749  maxtrain:0.4450402144772118  maxtest:0.4708333333333333\n",
    "# with params (22, 11): minloss:0.5759281516075134  maxtrain:0.6970509383378016  maxtest:0.50625\n",
    "# with params (22, 22): minloss:0.22360152006149292  maxtrain:0.8802502234137622  maxtest:0.63125\n",
    "# with params (22, 11, 6): minloss:0.4221361577510834  maxtrain:0.7658623771224308  maxtest:0.5625\n",
    "\n",
    "#red 2w epoch\n",
    "# with params (22, 11, 6): minloss:0.47377175092697144  maxtrain:0.6988382484361036  maxtest:0.5604166666666667\n",
    "# with params (22, 22): minloss:0.3008401095867157  maxtrain:0.7631814119749777  maxtest:0.5729166666666666\n",
    "# with params (33, 22): minloss:0.05082406476140022  maxtrain:0.9249329758713136  maxtest:0.5833333333333334\n",
    "\n",
    "#white 1w epoch\n",
    "# with params (33, 22): minloss:0.7508830428123474  maxtrain:0.558634772462077  maxtest:0.47346938775510206\n",
    "# with params (11, 11): minloss:1.0116682052612305  maxtrain:0.3879813302217036  maxtest:0.3904761904761905\n",
    "# with params (22, 11): minloss:0.9384194612503052  maxtrain:0.4547841306884481  maxtest:0.4272108843537415\n",
    "# with params (22, 22): minloss:0.8625235557556152  maxtrain:0.4323220536756126  maxtest:0.3653061224489796\n",
    "# with params (11, 6): minloss:0.9871591925621033  maxtrain:0.35939323220536756  maxtest:0.37210884353741497\n",
    "# with params (22, 6): minloss:0.9644197225570679  maxtrain:0.40373395565927656  maxtest:0.3843537414965986\\\n",
    "# with params (22, 11, 7): minloss:0.8957220315933228  maxtrain:0.5501750291715286  maxtest:0.5251700680272109\n",
    "# with params (22, 11, 7): minloss:1.0051820278167725  maxtrain:0.4203617269544924  maxtest:0.42448979591836733\n",
    "# with params (22, 11, 7): minloss:0.8748940825462341  maxtrain:0.544049008168028  maxtest:0.42108843537414964\n",
    "# with params (22, 22, 7): minloss:0.8348686099052429  maxtrain:0.41073512252042005  maxtest:0.37755102040816324\n",
    "# with params (22, 14, 7): minloss:0.9092842936515808  maxtrain:0.4632438739789965  maxtest:0.4346938775510204\n",
    "\n",
    "#white 2w epoch\n",
    "# with params (22, 11): minloss:0.9571816921234131  maxtrain:0.4235705950991832  maxtest:0.3979591836734694\n",
    "# with params (22, 22): minloss:0.8654391765594482  maxtrain:0.4209451575262544  maxtest:0.3761904761904762\n",
    "# with params (22, 22): minloss:0.7963970303535461  maxtrain:0.5705950991831972  maxtest:0.4489795918367347\n",
    "# with params (22, 6): minloss:0.9579921960830688  maxtrain:0.38039673278879815  maxtest:0.38299319727891157\n",
    "# with params (33, 22, 11): minloss:0.7382255792617798  maxtrain:0.4944574095682614  maxtest:0.4034013605442177"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch1.4] *",
   "language": "python",
   "name": "conda-env-torch1.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
