{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb10706a170>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVR,self).__init__()\n",
    "        self.fc1 = nn.Linear(11, 1)\n",
    "        self.fc2 = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVR()\n",
    "# optimizer=torch.optim.SGD(model.parameters(),lr=0.0005)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss加权重，减少数据标签数量差异的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = pd.read_csv('../data/winequality-white.csv',sep=';')\n",
    "wine_data = wine_data.values\n",
    "x = wine_data[:,:11]\n",
    "x_s = preprocessing.StandardScaler().fit(x)\n",
    "x = x_s.transform(x)\n",
    "y = wine_data[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6.0: 2198, 5.0: 1457, 7.0: 880, 8.0: 175, 4.0: 163, 3.0: 20, 9.0: 5})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "Y = torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "X_t = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "Y_t = torch.from_numpy(y_test).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(predicted, real):\n",
    "    precise_score = torch.round(predicted).detach().numpy()\n",
    "    return accuracy_score(precise_score, real.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zfj/anaconda3/envs/torch1.4/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([3428])) that is different to the input size (torch.Size([3428, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/zfj/anaconda3/envs/torch1.4/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1470])) that is different to the input size (torch.Size([1470, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10000], loss:31.8353\n",
      "train_score: 0.00\n",
      "test_score: 0.00\n",
      "test_loss: 31.7506\n",
      "\n",
      "epoch [201/10000], loss:25.8244\n",
      "train_score: 0.00\n",
      "test_score: 0.00\n",
      "test_loss: 25.6832\n",
      "\n",
      "epoch [401/10000], loss:19.3271\n",
      "train_score: 0.02\n",
      "test_score: 0.02\n",
      "test_loss: 19.2255\n",
      "\n",
      "epoch [601/10000], loss:15.9201\n",
      "train_score: 0.06\n",
      "test_score: 0.06\n",
      "test_loss: 15.9147\n",
      "\n",
      "epoch [801/10000], loss:14.2131\n",
      "train_score: 0.08\n",
      "test_score: 0.08\n",
      "test_loss: 14.2516\n",
      "\n",
      "epoch [1001/10000], loss:12.7084\n",
      "train_score: 0.08\n",
      "test_score: 0.09\n",
      "test_loss: 12.7693\n",
      "\n",
      "epoch [1201/10000], loss:11.0119\n",
      "train_score: 0.09\n",
      "test_score: 0.10\n",
      "test_loss: 11.1564\n",
      "\n",
      "epoch [1401/10000], loss:8.1237\n",
      "train_score: 0.13\n",
      "test_score: 0.10\n",
      "test_loss: 8.2710\n",
      "\n",
      "epoch [1601/10000], loss:4.5625\n",
      "train_score: 0.19\n",
      "test_score: 0.18\n",
      "test_loss: 4.4566\n",
      "\n",
      "epoch [1801/10000], loss:1.7382\n",
      "train_score: 0.30\n",
      "test_score: 0.31\n",
      "test_loss: 1.6311\n",
      "\n",
      "epoch [2001/10000], loss:0.8382\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.8430\n",
      "\n",
      "epoch [2201/10000], loss:0.7864\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7923\n",
      "\n",
      "epoch [2401/10000], loss:0.7831\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7893\n",
      "\n",
      "epoch [2601/10000], loss:0.7828\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7891\n",
      "\n",
      "epoch [2801/10000], loss:0.7827\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7890\n",
      "\n",
      "epoch [3001/10000], loss:0.7826\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7890\n",
      "\n",
      "epoch [3201/10000], loss:0.7824\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7889\n",
      "\n",
      "epoch [3401/10000], loss:0.7824\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7889\n",
      "\n",
      "epoch [3601/10000], loss:0.7823\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7888\n",
      "\n",
      "epoch [3801/10000], loss:0.7823\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7888\n",
      "\n",
      "epoch [4001/10000], loss:0.7823\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7888\n",
      "\n",
      "epoch [4201/10000], loss:0.7823\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7888\n",
      "\n",
      "epoch [4401/10000], loss:0.7823\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7888\n",
      "\n",
      "epoch [4601/10000], loss:0.7823\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7888\n",
      "\n",
      "epoch [4801/10000], loss:0.7823\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7888\n",
      "\n",
      "epoch [5001/10000], loss:0.7824\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7888\n",
      "\n",
      "epoch [5201/10000], loss:0.7824\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [5401/10000], loss:0.7824\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [5601/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [5801/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [6001/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [6201/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [6401/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [6601/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [6801/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [7001/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [7201/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [7401/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [7601/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [7801/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [8001/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [8201/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [8401/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [8601/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [8801/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [9001/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [9201/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [9401/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [9601/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n",
      "epoch [9801/10000], loss:0.7825\n",
      "train_score: 0.45\n",
      "test_score: 0.44\n",
      "test_loss: 0.7887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOTAL_EPOCH = 10000\n",
    "for epoch in range(TOTAL_EPOCH):\n",
    "    optimizer.zero_grad()\n",
    "    predicted = model(X)\n",
    "    loss = criterion(predicted, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 200 == 0:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, TOTAL_EPOCH, loss))\n",
    "        print('train_score: {:.2f}'.format(calc_acc(predicted, Y)))\n",
    "        with torch.no_grad():\n",
    "            t_predicted = model(X_t)\n",
    "            print('test_score: {:.2f}'.format(calc_acc(t_predicted, Y_t)))\n",
    "            print('test_loss: {:.4f}\\n'.format(criterion(t_predicted, Y_t)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6.0: 1466, 7.0: 3, 8.0: 1})\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    t_predicted = model(X_t)\n",
    "    result = torch.round(t_predicted).detach().numpy()[:,0]\n",
    "    print(Counter(result))\n",
    "    \n",
    "# Counter({6.0: 1118, 5.0: 351, 8.0: 1})\n",
    "# Counter({6.0: 1466, 7.0: 3, 8.0: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_score: 0.41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    t_predicted = model(X_t)\n",
    "    print('test_score: {:.2f}\\n'.format(calc_acc(t_predicted, Y_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam 11-11-1 lr=0.001  loss-0.792  train-0.44  test-0.44\n",
    "# SGD-relu 11-11-1 lr=0.0005  loss-0.792  train-0.44  test-0.44\n",
    "# adam 11-6-1 lr=0.001  loss-0.7725  train-0.447  test-0.45\n",
    "# adam 11-4-1 lr=0.001  loss-0.7942  train-0.45  test-0.45\n",
    "# adam-relu 11-1-1 lr=0.001  loss-0.8052  train-0.44  test-0.47\n",
    "\n",
    "# SGD 11-1 lr=0.0005  loss-0.7909  train-0.45  test-0.45"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch1.4] *",
   "language": "python",
   "name": "conda-env-torch1.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
